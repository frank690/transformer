# Transformer
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Imports: isort](https://img.shields.io/badge/%20imports-isort-%231674b1?style=flat&labelColor=ef8336)](https://pycqa.github.io/isort/)

## What is this?
This repo represents my implementation of the famous transformer paper ["Attention Is All You Need"](https://arxiv.org/pdf/1706.03762.pdf).

## Who did this?
This is a solo project by me

## When was this done?
This project was done in the fall of 2023, using Python 3.11.4

## What is left to do?

- [x] Implement data preprocessing
    - [x] Download data
    - [x] Tokenization
    - [x] Create dataset / data loader
- [x] Implement positional encoding
- [x] Implement encoder
- [x] Implement decoder
- [ ] Implement transformer
- [ ] Implement training routine
- [ ] Test it all


## What data is used?
German-English translation dataset (WMT17) is used. 
The dataset can be downloaded from [here](https://www.statmt.org/wmt17/translation-task.html#download).
